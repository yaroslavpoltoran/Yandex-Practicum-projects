{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"NLP project.ipynb","provenance":[{"file_id":"12Tjgbszyc9aHNfJL5M6rMaoUKz1rvVvC","timestamp":1591232273898}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"nzsllrPY1sFL","colab_type":"text"},"source":["# Описание проекта"]},{"cell_type":"markdown","metadata":{"id":"loOG35yX1U2z","colab_type":"text"},"source":["Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n","\n","Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n","\n","Постройте модель со значением метрики качества *F1* не меньше 0.75. \n","\n","### Инструкция по выполнению проекта\n","\n","1. Загрузите и подготовьте данные.\n","2. Обучите разные модели. \n","3. Сделайте выводы.\n","\n","\n","### Описание данных\n","\n","Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."]},{"cell_type":"markdown","metadata":{"id":"oNHEdMdH1U20","colab_type":"text"},"source":["# 1. Подготовка"]},{"cell_type":"code","metadata":{"id":"BGU3NAN71U20","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from catboost import CatBoostClassifier\n","import lightgbm as lgb\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import train_test_split\n","import time\n","from sklearn.utils import shuffle\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import accuracy_score"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oRUXU-nt1U23","colab_type":"code","outputId":"b906a141-86f4-45ad-e57f-4788c87f8eb1","colab":{}},"source":["import nltk\n","from nltk.tokenize import RegexpTokenizer\n","from nltk.stem import SnowballStemmer\n","from nltk.corpus import stopwords as nltk_stopwords\n","nltk.download('stopwords')\n","from sklearn.feature_extraction.text import TfidfVectorizer"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\poltoran\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Xueq-mE71U27","colab_type":"code","colab":{}},"source":["import torch\n","import transformers as ppb\n","from pytorch_pretrained_bert import BertTokenizer\n","from tqdm import notebook"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jAjdbycl1U29","colab_type":"text"},"source":["Посмотрим на таблицу:"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"mM00-g-11U2-","colab_type":"code","outputId":"39b00cad-41d8-4236-cc54-cebfa69b31ef","colab":{}},"source":["df = pd.read_csv('/datasets/toxic_comments.csv')\n","df.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>toxic</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>Explanation\\nWhy the edits made under my usern...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>D'aww! He matches this background colour I'm s...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>Hey man, I'm really not trying to edit war. It...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>You, sir, are my hero. Any chance you remember...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text  toxic\n","0  Explanation\\nWhy the edits made under my usern...      0\n","1  D'aww! He matches this background colour I'm s...      0\n","2  Hey man, I'm really not trying to edit war. It...      0\n","3  \"\\nMore\\nI can't make any real suggestions on ...      0\n","4  You, sir, are my hero. Any chance you remember...      0"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"wjBZTxcx1U3A","colab_type":"code","outputId":"ad7a1142-9465-4bb5-e01f-587eb0f5ffac","colab":{}},"source":["print('Количество строк в датафрейме:', df.shape[0])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Количество строк в датафрейме: 159571\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Uq1r6cTl1U3D","colab_type":"text"},"source":["Таблица состоит из двух столбцов, toxic - целевой признак. В столбце text приведем все сообщения к нижнему регистру."]},{"cell_type":"code","metadata":{"id":"5PR6WzS61U3D","colab_type":"code","colab":{}},"source":["df.text = df.text.str.lower()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SwUUQa8h1U3G","colab_type":"text"},"source":["Оценим дисбаланс классов:"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"oi2T8-Je1U3H","colab_type":"code","outputId":"28e5dcf7-f56e-4c7f-9753-0c8c1f432df7","colab":{}},"source":["df.toxic.value_counts(normalize=True)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    0.898321\n","1    0.101679\n","Name: toxic, dtype: float64"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"SoQuYOvl1U3J","colab_type":"text"},"source":["Наблюдается сильный дисбаланс (10% класса \"1\" и 90% класса \"0\"). Это наблюдение дает нам значение accuracy для оценки адекватности моделей: accuracy моделей должна быть больше 90%."]},{"cell_type":"markdown","metadata":{"id":"TeI2rDYA1U3K","colab_type":"text"},"source":["# 2. Обучение"]},{"cell_type":"markdown","metadata":{"id":"cOXu5psa1U3K","colab_type":"text"},"source":["### 2.1. Построение моделей с применением TF-IDF "]},{"cell_type":"markdown","metadata":{"id":"AtxTsBQl1U3L","colab_type":"text"},"source":["Созданим копию датафрейма для дальнейшего использования:"]},{"cell_type":"code","metadata":{"id":"HG41bypM1U3L","colab_type":"code","colab":{}},"source":["df_tf_idf = df.copy()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CqlHWFzx1U3N","colab_type":"text"},"source":["Напишем функцию, которая принимает на вход неподготовленный текст, а возвращает его после очистки, токенизации, стемминга и обратной склейки в list:"]},{"cell_type":"code","metadata":{"id":"5cSksHco1U3O","colab_type":"code","colab":{}},"source":["stemmer_tf_idf = SnowballStemmer(\"english\")\n","tokenizer_tf_idf = RegexpTokenizer(r'\\w{2,}')\n","\n","def clean_stemm(text):\n","    new_words = tokenizer_tf_idf.tokenize(text)\n","    new_list = []\n","    for w in new_words:\n","        w = stemmer_tf_idf.stem(w)\n","        new_list.append(w)\n","    new_list = ' '.join(new_list)\n","    return new_list"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Y-WU00Q1U3Q","colab_type":"text"},"source":["Применим функцию к датафрейму и созданим новый столбец с текстом после очистки и стемминга stem_text:"]},{"cell_type":"code","metadata":{"id":"qlK6W8KO1U3R","colab_type":"code","outputId":"8734c157-597c-4f1f-ce3e-ecca2a23c09c","colab":{}},"source":["%%time\n","df_tf_idf['stem_text'] = df_tf_idf['text'].apply(clean_stemm)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Wall time: 1min 54s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9bNXUt811U3U","colab_type":"text"},"source":["Разделим датафрейм на признак и на на целевой признак, далее разделим их на обучающую и тестовую выборки:"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"SRA13QdH1U3U","colab_type":"code","outputId":"41af174a-c468-4eed-8845-4187f03a3049","colab":{}},"source":["%%time\n","corpus_tf_idf = df_tf_idf['stem_text'].values.astype('U')\n","target_tf_idf = df_tf_idf['toxic']\n","\n","train_features_tf_idf, test_features_tf_idf, train_target_tf_idf, test_target_tf_idf = train_test_split(\n","corpus_tf_idf, target_tf_idf, test_size=0.2, random_state=42)\n","\n","# Выведем информацию о размерах выборок, чтобы убедиться в правильной разбивке\n","print('Количество строк в обучающей выборке:', train_features_tf_idf.shape[0])\n","print('Количество строк в тестовой выборке:', test_features_tf_idf.shape[0])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Количество строк в обучающей выборке: 127656\n","Количество строк в тестовой выборке: 31915\n","Wall time: 4.67 s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HUZhM4My1U3W","colab_type":"text"},"source":["Вычислим TF-IDF для корпуса текстов с учетом стоп-слов. Так как данные разделены на обучающую и тестовую выборки, функцию fit() запустим только на обучающей:"]},{"cell_type":"code","metadata":{"id":"mr8vyU4j1U3X","colab_type":"code","colab":{}},"source":["stopwords = set(nltk_stopwords.words('english'))\n","\n","count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n","tf_idf_train = count_tf_idf.fit_transform(train_features_tf_idf)\n","tf_idf_test = count_tf_idf.transform(test_features_tf_idf)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QcHNr91u1U3Z","colab_type":"text"},"source":["Данные для обучения моделей готовы. Приступаем к обучению нескольких моделей. Первой будет Логистическая регрессия. Ввиду дисбаланса классов будем использовать class_weight = 'balanced':"]},{"cell_type":"code","metadata":{"id":"HzVON-nO1U3a","colab_type":"code","outputId":"df488021-df27-4e8c-d2e0-a621018ee3a0","colab":{}},"source":["%%time\n","\n","model_lr_tf_idf = LogisticRegression(random_state=12345, solver='lbfgs', class_weight = 'balanced')\n","model_lr_tf_idf.fit(tf_idf_train, train_target_tf_idf)\n","predicted_lr_tf_idf = model_lr_tf_idf.predict(tf_idf_test)\n","accuracy_lr_tf_idf = accuracy_score(test_target_tf_idf, predicted_lr_tf_idf)\n","f1_score_lr_tf_idf = f1_score(test_target_tf_idf, predicted_lr_tf_idf)\n","\n","probabilities_test_lr_tf_idf = model_lr_tf_idf.predict_proba(tf_idf_test)\n","probabilities_one_test_lr_tf_idf = probabilities_test_lr_tf_idf[:, 1]\n","auc_roc_lr_tf_idf = roc_auc_score(test_target_tf_idf, probabilities_one_test_lr_tf_idf)\n","\n","print('Логистическая регрессия:')\n","print('accuracy:', accuracy_lr_tf_idf.round(decimals=3))\n","print('f1_score:', f1_score_lr_tf_idf.round(decimals=3))\n","print('auc_roc:', auc_roc_lr_tf_idf.round(decimals=3))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Логистическая регрессия:\n","accuracy: 0.942\n","f1_score: 0.752\n","auc_roc: 0.973\n","Wall time: 3.77 s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rOCa86fz1U3c","colab_type":"text"},"source":["Случайный лес:"]},{"cell_type":"code","metadata":{"id":"axzZaFer1U3c","colab_type":"code","outputId":"e0f9101d-88c5-4d8f-8955-7930a96b82b8","colab":{}},"source":["max_depth_list1 = []; n_estimators_list1 = []; accuracy_list1 = []; f1_score_list1 = []; auc_roc_list1 = []\n","\n","for i in range(1, 16, 1):\n","    model_rf_tf_idf = RandomForestClassifier(n_estimators=10, max_depth=i, random_state=12345, class_weight='balanced')\n","    model_rf_tf_idf.fit(tf_idf_train, train_target_tf_idf)\n","    predicted_rf_tf_idf = model_rf_tf_idf.predict(tf_idf_test)\n","    accuracy_rf_tf_idf = accuracy_score(test_target_tf_idf, predicted_rf_tf_idf)\n","    f1_score_rf_tf_idf = f1_score(test_target_tf_idf, predicted_rf_tf_idf)\n","\n","    probabilities_test_rf_tf_idf = model_rf_tf_idf.predict_proba(tf_idf_test)\n","    probabilities_one_test_rf_tf_idf = probabilities_test_rf_tf_idf[:, 1]\n","    auc_roc_rf_tf_idf = roc_auc_score(test_target_tf_idf, probabilities_one_test_rf_tf_idf)\n","    \n","    max_depth_list1.append(i)\n","    n_estimators_list1.append('10')\n","    accuracy_list1.append(accuracy_rf_tf_idf)\n","    f1_score_list1.append(f1_score_rf_tf_idf)\n","    auc_roc_list1.append(auc_roc_rf_tf_idf)\n","    \n","top1_rf_f1_score = pd.DataFrame({'max_depth': max_depth_list1, \n","                             'n_estimators':n_estimators_list1,\n","                             'accuracy': accuracy_list1,\n","                             'f1_score': f1_score_list1,\n","                             'auc_roc': auc_roc_list1\n","                             })\n","print(top1_rf_f1_score.sort_values('f1_score', ascending=False).head(2))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["    max_depth n_estimators  accuracy  f1_score   auc_roc\n","14         15           10  0.621745  0.307322  0.797798\n","13         14           10  0.614351  0.300523  0.789242\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6rRH5YML1U3h","colab_type":"code","outputId":"0996b1da-2bc3-4b2a-9c25-e1f537ddf9d5","colab":{}},"source":["max_depth_list2 = []; n_estimators_list2 = []; accuracy_list2 = []; f1_score_list2 = []; auc_roc_list2 = []\n","\n","for j in range(10, 211, 20):\n","    model_rf_tf_idf = RandomForestClassifier(n_estimators=j, max_depth=15, random_state=12345, class_weight='balanced')\n","    model_rf_tf_idf.fit(tf_idf_train, train_target_tf_idf)\n","    predicted_rf_tf_idf = model_rf_tf_idf.predict(tf_idf_test)\n","    accuracy_rf_tf_idf = accuracy_score(test_target_tf_idf, predicted_rf_tf_idf)\n","    f1_score_rf_tf_idf = f1_score(test_target_tf_idf, predicted_rf_tf_idf)\n","\n","    probabilities_test_rf_tf_idf = model_rf_tf_idf.predict_proba(tf_idf_test)\n","    probabilities_one_test_rf_tf_idf = probabilities_test_rf_tf_idf[:, 1]\n","    auc_roc_rf_tf_idf = roc_auc_score(test_target_tf_idf, probabilities_one_test_rf_tf_idf)\n","    \n","    max_depth_list2.append('15')\n","    n_estimators_list2.append(j)\n","    accuracy_list2.append(accuracy_rf_tf_idf)\n","    f1_score_list2.append(f1_score_rf_tf_idf)\n","    auc_roc_list2.append(auc_roc_rf_tf_idf)\n","    \n","top2_rf_f1_score = pd.DataFrame({'max_depth': max_depth_list2, \n","                             'n_estimators':n_estimators_list2,\n","                             'accuracy': accuracy_list2,\n","                             'f1_score': f1_score_list2,\n","                             'auc_roc': auc_roc_list2\n","                             })\n","print(top2_rf_f1_score.sort_values('f1_score', ascending=False).head(2))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["   max_depth  n_estimators  accuracy  f1_score   auc_roc\n","8         15           170  0.708319  0.373680  0.881702\n","10        15           210  0.707536  0.373389  0.880655\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"w_qJogj_1U3j","colab_type":"text"},"source":["Результаты случайного леса плохи, скорей всего нужно применять больше деревьев. Остановимся пока на таких значениях.\n","\n","Обучим модель catBoost:"]},{"cell_type":"code","metadata":{"id":"SUp_3a2s1U3k","colab_type":"code","outputId":"ced9204d-d435-4d9d-d8e2-99e61c4dc095","colab":{}},"source":["%%time\n","model_cat_tf_idf = CatBoostClassifier(iterations=1000,\n","                                      random_seed = 42,\n","                                      metric_period = 50,\n","                                      eval_metric = 'F1',\n","                                      learning_rate = 0.5,\n","                                      early_stopping_rounds = 50, \n","                                      #task_type=\"GPU\", \n","                                      #devices='0:1'\n","                                     )\n","model_cat_tf_idf.fit(tf_idf_train, train_target_tf_idf, verbose=200)\n","predicted_cat_tf_idf = model_cat_tf_idf.predict(tf_idf_test)\n","accuracy_cat_tf_idf = accuracy_score(test_target_tf_idf, predicted_cat_tf_idf)\n","f1_score_cat_tf_idf = f1_score(test_target_tf_idf, predicted_cat_tf_idf)\n","\n","probabilities_test_cat_tf_idf = model_cat_tf_idf.predict_proba(tf_idf_test)\n","probabilities_one_test_cat_tf_idf = probabilities_test_cat_tf_idf[:, 1]\n","auc_roc_cat_tf_idf = roc_auc_score(test_target_tf_idf, probabilities_one_test_cat_tf_idf)\n","\n","print('CatBoost:')\n","print('accuracy:', accuracy_cat_tf_idf.round(decimals=3))\n","print('f1_score:', f1_score_cat_tf_idf.round(decimals=3))\n","print('auc_roc:', auc_roc_cat_tf_idf.round(decimals=3))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0:\tlearn: 0.3860659\ttotal: 1.01s\tremaining: 16m 53s\n","200:\tlearn: 0.8173763\ttotal: 2m 35s\tremaining: 10m 19s\n","400:\tlearn: 0.8400955\ttotal: 5m 11s\tremaining: 7m 44s\n","600:\tlearn: 0.8524854\ttotal: 7m 44s\tremaining: 5m 8s\n","800:\tlearn: 0.8684387\ttotal: 10m 19s\tremaining: 2m 33s\n","999:\tlearn: 0.8942042\ttotal: 12m 52s\tremaining: 0us\n","CatBoost:\n","accuracy: 0.96\n","f1_score: 0.78\n","auc_roc: 0.965\n","Wall time: 13min 1s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GTeS4sqz1U3m","colab_type":"text"},"source":["Теперь обучим LightGBM на стандартных настройках гиперпараметров:"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"lLpT8zja1U3m","colab_type":"code","outputId":"65a570a7-2bcd-473e-8789-762cf0b9a1a3","colab":{}},"source":["%%time\n","model_lgb_tf_idf = lgb.LGBMClassifier()\n","model_lgb_tf_idf.fit(tf_idf_train, train_target_tf_idf)\n","predicted_lgb_tf_idf = model_lgb_tf_idf.predict(tf_idf_test)\n","accuracy_lgb_tf_idf = accuracy_score(test_target_tf_idf, predicted_lgb_tf_idf)\n","f1_score_lgb_tf_idf = f1_score(test_target_tf_idf, predicted_lgb_tf_idf)\n","\n","probabilities_test_lgb_tf_idf = model_lgb_tf_idf.predict_proba(tf_idf_test)\n","probabilities_one_test_lgb_tf_idf = probabilities_test_lgb_tf_idf[:, 1]\n","auc_roc_lgb_tf_idf = roc_auc_score(test_target_tf_idf, probabilities_one_test_lgb_tf_idf)\n","\n","print('LightGBM:')\n","print('accuracy:', accuracy_lgb_tf_idf.round(decimals=3))\n","print('f1_score:', f1_score_lgb_tf_idf.round(decimals=3))\n","print('auc_roc:', auc_roc_lgb_tf_idf.round(decimals=3))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["LightGBM:\n","accuracy: 0.959\n","f1_score: 0.763\n","auc_roc: 0.965\n","Wall time: 24.8 s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5z4UAtLl1U3o","colab_type":"text"},"source":["##### Выводы по пункту 2.1:\n","Три из четырех моделей превзошли необходимое значение f1>=0.75. Модель логистической регрессии обучилась быстрее бустингов (4 сек), но показала наименьший результат f1=0.752. CatBoost показал наибольшее значение  f1=0.78, но обучался дольше всех (13 мин). LightGBM - \"среднячок\" с f1=0.763 и временем обучения 25 сек. Более наглядное представление результатов в виде таблице приведено в конце работы."]},{"cell_type":"markdown","metadata":{"id":"vyYdRu7i1U3o","colab_type":"text"},"source":["### 2.2. Построение моделей с применением BERT"]},{"cell_type":"markdown","metadata":{"id":"i7CS_FE-1U3p","colab_type":"text"},"source":["Из датафрейма получим выборку с равным количеством классов \"1\" и \"0\". Общий размер выборки примем в 2000 ввиду долгой работы модели BERT:"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"s_TVaQMF1U3p","colab_type":"code","outputId":"49a82388-c009-4810-bc05-94b2178ea782","colab":{}},"source":["df_bert_ones = df[df['toxic']==1].sample(1000).reset_index(drop=True)\n","df_bert_zeros = df[df['toxic']==0].sample(1000).reset_index(drop=True)\n","df_bert = pd.concat([df_bert_ones] + [df_bert_zeros]).reset_index(drop=True)\n","df_bert = shuffle(df_bert, random_state=12345).reset_index(drop=True)\n","# Проверим правильность разбиения выборки по классам\n","df_bert.toxic.value_counts()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    1000\n","0    1000\n","Name: toxic, dtype: int64"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"_W6gza8k1U3r","colab_type":"text"},"source":["Создаем токенайзер для модели BERT:"]},{"cell_type":"code","metadata":{"id":"D3c3KTIW1U3r","colab_type":"code","colab":{}},"source":["tokenizer = ppb.BertTokenizer.from_pretrained('bert-base-uncased')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2ygGVIwk1U3t","colab_type":"text"},"source":["Токенизируем текст каждого твита (строки). В таблице есть строки, превыщающие длину в 512 токенов. Ограничим максимальную длину."]},{"cell_type":"code","metadata":{"id":"JF_bX7Ky1U3t","colab_type":"code","colab":{}},"source":["tokenized = df_bert['text'].apply((lambda x: tokenizer.encode(x, max_length=512, add_special_tokens=True)) )"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jtEcPPSd1U3w","colab_type":"text"},"source":["Инициализируем предобученную модель BERT из файла, в json-файле конфигурации описаны параметры модели:"]},{"cell_type":"code","metadata":{"id":"XOg9E77-1U3w","colab_type":"code","colab":{}},"source":["config = ppb.BertConfig.from_pretrained('bert-base-uncased')\n","model = ppb.BertModel.from_pretrained('bert-base-uncased', config = config)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-WrigN6Y1U3y","colab_type":"text"},"source":["Из-за того, что каждый твит в датасете имеет разную длину (количество токенов) мы делаем паддинг - заполнение нулями каждого массива токенов до длины максимального массива чтобы на выходе получить матрицу из токенизированных текстов одной длины:"]},{"cell_type":"code","metadata":{"id":"l_MmS74v1U3y","colab_type":"code","colab":{}},"source":["len_list = tokenized.apply(lambda x: len(x))\n","max_len = max(len_list)\n","\n","padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n","# Накладываем маску на значимые токены\n","# В данном случае нам важны все слова кроме нулевых токенов, появившихся на предыдущем шаге паддинга\n","attention_mask = np.where(padded != 0, 1, 0)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hZ5WcJJ81U30","colab_type":"text"},"source":["Теперь сформируем вектора текстов с помощью модели BERT:"]},{"cell_type":"code","metadata":{"id":"c2SW0W8f1U30","colab_type":"code","outputId":"c00da40e-9a97-435f-bd1e-111736db2cdd","colab":{"referenced_widgets":["3296ae519f024780ad67291be03105aa"]}},"source":["batch_size = 50\n","embeddings = []\n","\n","for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n","        input_ids = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n","        \n","        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n","        \n","        with torch.no_grad():\n","            last_hidden_states = model(input_ids, attention_mask=attention_mask_batch)\n","\n","        embeddings.append(last_hidden_states[0][:,0,:].numpy())"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3296ae519f024780ad67291be03105aa","version_major":2,"version_minor":0},"text/plain":["HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Qs1cguBI1U32","colab_type":"text"},"source":["Преобразуем список батчей эмбеддингов в numpy-матрицу, в другую матрицу запишем значения целевого признака, и разделим матрицы на обучающую и тестовую выборки."]},{"cell_type":"code","metadata":{"id":"DtMnBwMq1U33","colab_type":"code","colab":{}},"source":["features = np.concatenate(embeddings)\n","labels = df_bert['toxic']\n","train_features, test_features, train_labels, test_labels = train_test_split(features, labels, \n","                                                                            test_size=0.25, random_state=42)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3e5YCq951U34","colab_type":"text"},"source":["Все готово для обучения моделей: логистической регрессии, LightGBM и CatBoost."]},{"cell_type":"code","metadata":{"id":"EnLKr31B1U35","colab_type":"code","outputId":"bf22d793-2fcc-4729-da60-e28309febbe2","colab":{}},"source":["%%time\n","model_lr = LogisticRegression(solver = 'lbfgs', class_weight = 'balanced', max_iter = 1000)\n","model_lr.fit(train_features, train_labels)\n","predicted_lr = model_lr.predict(test_features)\n","accuracy_lr = accuracy_score(test_labels, predicted_lr)\n","f1_score_lr = f1_score(test_labels, predicted_lr)\n","\n","probabilities_test_lr = model_lr.predict_proba(test_features)\n","probabilities_one_test_lr = probabilities_test_lr[:, 1]\n","auc_roc_lr = roc_auc_score(test_labels, probabilities_one_test_lr)\n","\n","print('Логистическая регрессия:')\n","print('accuracy:', accuracy_lr.round(decimals=3))\n","print('f1_score:', f1_score_lr.round(decimals=3))\n","print('auc_roc:', auc_roc_lr.round(decimals=3))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Логистическая регрессия:\n","accuracy: 0.864\n","f1_score: 0.865\n","auc_roc: 0.949\n","Wall time: 366 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Jrwm5wOE1U37","colab_type":"code","outputId":"e7121c00-740a-43d5-e02c-565341cb6ed8","colab":{}},"source":["%%time\n","model_lgb = lgb.LGBMClassifier()\n","model_lgb.fit(train_features, train_labels)\n","predicted_lgb = model_lgb.predict(test_features)\n","accuracy_lgb = accuracy_score(test_labels, predicted_lgb)\n","f1_score_lgb = f1_score(test_labels, predicted_lgb)\n","\n","probabilities_test_lgb = model_lgb.predict_proba(test_features)\n","probabilities_one_test_lgb = probabilities_test_lgb[:, 1]\n","auc_roc_lgb = roc_auc_score(test_labels, probabilities_one_test_lgb)\n","\n","print('LightGBM:')\n","print('accuracy:', accuracy_lgb.round(decimals=3))\n","print('f1_score:', f1_score_lgb.round(decimals=3))\n","print('auc_roc:', auc_roc_lgb.round(decimals=3))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["LightGBM:\n","accuracy: 0.856\n","f1_score: 0.858\n","auc_roc: 0.939\n","Wall time: 4.43 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"6mWhXzAa1U39","colab_type":"code","outputId":"bc716cd2-6e6e-435c-c015-859f0b99a450","colab":{}},"source":["%%time\n","model_cat = CatBoostClassifier(iterations=1000,\n","                               random_seed = 42,\n","                               metric_period = 50,\n","                               eval_metric = 'F1',\n","                               learning_rate = 0.5,\n","                               early_stopping_rounds = 50, \n","                               #task_type=\"GPU\", \n","                               #devices='0:1'\n","                              )\n","\n","model_cat.fit(train_features, train_labels, verbose=200)\n","predicted_cat = model_cat.predict(test_features)\n","accuracy_cat = accuracy_score(test_labels, predicted_cat)\n","f1_score_cat = f1_score(test_labels, predicted_cat)\n","\n","probabilities_test_cat = model_cat.predict_proba(test_features)\n","probabilities_one_test_cat = probabilities_test_cat[:, 1]\n","auc_roc_cat = roc_auc_score(test_labels, probabilities_one_test_cat)\n","\n","print('CatBoost:')\n","print('accuracy:', accuracy_cat.round(decimals=3))\n","print('f1_score:', f1_score_cat.round(decimals=3))\n","print('auc_roc:', auc_roc_cat.round(decimals=3))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0:\tlearn: 0.7500000\ttotal: 77.8ms\tremaining: 1m 17s\n","200:\tlearn: 1.0000000\ttotal: 13.6s\tremaining: 54s\n","400:\tlearn: 1.0000000\ttotal: 27.4s\tremaining: 40.9s\n","600:\tlearn: 1.0000000\ttotal: 41.6s\tremaining: 27.6s\n","800:\tlearn: 1.0000000\ttotal: 55.5s\tremaining: 13.8s\n","999:\tlearn: 1.0000000\ttotal: 1m 9s\tremaining: 0us\n","CatBoost:\n","accuracy: 0.858\n","f1_score: 0.862\n","auc_roc: 0.937\n","Wall time: 1min 9s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"t71cV16P1U3_","colab_type":"text"},"source":["##### Выводы по пункту 2.2:\n","Все использованные модели сильно превысили необходимое значение метрики F1=0.75, показав результаты F1>=0.858. Также все модели сильно превысили порог адекватности в accuracy=0.5 показав результат accuracy>=0.856. Результаты в виде таблицы приведены в пунтке 3 данной работы."]},{"cell_type":"markdown","metadata":{"id":"DtDEeJw01U4A","colab_type":"text"},"source":["# 3. Выводы"]},{"cell_type":"markdown","metadata":{"id":"Vk0cHcvk1U4A","colab_type":"text"},"source":["Модели с применением TF-IDF:\n","\n","Метрика        | Log.Reg | CatBoost | LightGBM\n",":------------- | ------- | -------- | ------- \n","Accuracy       | 0.942   | 0.96     | 0.959  \n","F1             | 0.752   | 0.78     | 0.763\n","ROC-AUC        | 0.973   | 0.965    | 0.965\n","Время обучения | 4 сек   | 13 мин   | 25 сек\n","\n","Модели с применением BERT:\n","\n","Метрика        | Log.Reg | CatBoost | LightGBM\n",":------------- | ------- | -------- | ------- \n","Accuracy       | 0.864   | 0.858    | 0.856  \n","F1             | 0.865   | 0.862    | 0.858\n","ROC-AUC        | 0.949   | 0.937    | 0.939\n","Время обучения | <1 сек  | 1 мин    | 4 сек"]},{"cell_type":"markdown","metadata":{"id":"IubPxsl71U4A","colab_type":"text"},"source":["- Все модели (кроме случайного леса) превысили необходимое значение метрики F=0.75.\n","- С применением TF-IDF лучшей моделью по значению метрики F1 является CatBoost (F1=0.78). Однако у нее самое большое время обучения - 13 мин.\n","- С применением BERT лучшей моделью по значению метрики F1 является логистическая регрессия (F1=0.865). У нее также самые большие значения Accuracy=0.864 и ROC-AUC=0.949 и наименьшее время обучения (<1 сек) по сравнению с CatBoost и LightGBM."]}]}